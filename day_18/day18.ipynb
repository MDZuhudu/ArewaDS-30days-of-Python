{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 18\n",
    "## Exercises: Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 'love'), (5, 'you'), (3, 'can'), (2, 'what'), (2, 'teaching'), (2, 'not'), (2, 'else'), (2, 'do'), (2, 'I'), (1, 'which'), (1, 'to'), (1, 'the'), (1, 'something'), (1, 'if'), (1, 'give'), (1, 'develop'), (1, 'capabilities'), (1, 'application'), (1, 'an'), (1, 'all'), (1, 'Python'), (1, 'If')]\n"
     ]
    }
   ],
   "source": [
    "#What is the most frequent word in the following paragraph?\n",
    "\n",
    "import re\n",
    "\n",
    "paragraph = '''I love teaching. If you do not love teaching what else can you love. I love Python if you do not love something which can give you all the capabilities to develop an application what else can you love.'''\n",
    "\n",
    "most_frequent_word = {}\n",
    "\n",
    "paragraph = paragraph.replace('.', '').split()\n",
    "for p in paragraph:\n",
    "    if p in most_frequent_word:\n",
    "        most_frequent_word[p] += 1\n",
    "    else:\n",
    "        most_frequent_word[p] = 1\n",
    "\n",
    "l = [(v, k) for k,v in most_frequent_word.items()]  \n",
    "l.sort(reverse=True)  \n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-12', '-4', '-3', '-1', '0', '4', '8']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction. \n",
    "#Extract these numbers from this whole text and find the distance between the two furthest particles.\n",
    "\n",
    "sentence = \"The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction. Extract these numbers from this whole text and find the distance between the two furthest particles.\"\n",
    "\n",
    "reg_pattern = r'[-]?\\d+'\n",
    "points = re.findall(reg_pattern, sentence)\n",
    "print(points)\n",
    "\n",
    "distance = int(points[-1]) - int(points[1])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Write a pattern which identifies if a string is a valid python variable\n",
    "\n",
    "def is_valid_variable(word):\n",
    "    reg_pattern = r'^[a-z_]\\w*$'\n",
    "    if  re.search(reg_pattern, word, re.IGNORECASE):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(is_valid_variable('first_name')) # True\n",
    "print(is_valid_variable('first-name')) # False\n",
    "print(is_valid_variable('1first_name')) # False\n",
    "print(is_valid_variable('firstname')) # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a teacher and I love teaching. There is nothing as more rewarding as educating and empowering people. I found teaching more interesting than any other jobs. Does this motivate you to be a teacher\n",
      "[(3, 'I'), (2, 'teacher'), (2, 'more')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Clean the following text. After cleaning, count three most frequent words in the string.\n",
    "\n",
    "\n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''\n",
    "\n",
    "def clean_text(sentence = sentence):\n",
    "    clean = re.sub('[%@$#&;!?,]', \"\", sentence).split()\n",
    "    return clean\n",
    "\n",
    "print(*clean_text())\n",
    "\n",
    "def most_frequent_word(words, number_of_words):\n",
    "    freq_word = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word in freq_word:\n",
    "            freq_word[word] += 1\n",
    "        else:\n",
    "            freq_word[word] = 1\n",
    "    \n",
    "\n",
    "    list = [(val,key) for key,val in freq_word.items()]\n",
    "    list.sort(reverse=True)\n",
    "    \n",
    "    return list[:number_of_words]\n",
    "\n",
    "print(most_frequent_word(clean_text(), 3))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arewadatascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
