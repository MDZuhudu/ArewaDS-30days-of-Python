{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words in http://www.gutenberg.org/files/1112/1112.txt is: [(593, ''), (23, '<li><a'), (18, '/>'), (13, '<meta'), (7, '<li>'), (7, '<input'), (7, '<a'), (7, '</li>'), (6, 'property=og'), (6, '<link')]\n"
     ]
    }
   ],
   "source": [
    "#Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "response = requests.get(romeo_and_juliet)\n",
    "words = response.text\n",
    "words = re.sub(r'[.,;\"-]', '', words)\n",
    "words = re.sub(r'[:\\n]', ' ', words) \n",
    "words = re.split(' ', words)\n",
    "count = []\n",
    "for i in words:\n",
    "    if (words.count(i), i) not in count:\n",
    "        count.append((words.count(i), i))\n",
    "s_count = sorted(count, reverse=True)\n",
    "print(f'The most frequent words in {romeo_and_juliet} is: {s_count[ : 10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHT DATA\n",
      "Standard Deviation: 1.06\n",
      "Minimum: 3.0\n",
      "Maximum: 7.5\n",
      "Median: 4.5\n",
      "Mean: 4.71\n",
      "LIFESPAN DATA\n",
      "Standard Deviation: 1.57\n",
      "Minimum: 10.5\n",
      "Maximum: 19.0\n",
      "Median: 13.5\n",
      "Mean: 13.75\n",
      "defaultdict(<class 'int'>, {'Egypt': 3, 'Greece': 1, 'United States': 28, 'United Arab Emirates': 1, 'Australia': 1, 'France': 2, 'United Kingdom': 8, 'Burma': 2, 'Canada': 3, 'Cyprus': 1, 'Russia': 4, 'China': 1, 'Japan': 1, 'Thailand': 4, 'Isle of Man': 1, 'Norway': 1, 'Iran (Persia)': 1, 'Singapore': 1, 'Somalia': 1, 'Turkey': 2})\n",
      "defaultdict(<class 'int'>, {'Egypt': 3, 'Greece': 1, 'United States': 28, 'United Arab Emirates': 1, 'Australia': 1, 'France': 2, 'United Kingdom': 8, 'Burma': 2, 'Canada': 3, 'Cyprus': 1, 'Russia': 4, 'China': 1, 'Japan': 1, 'Thailand': 4, 'Isle of Man': 1, 'Norway': 1, 'Iran (Persia)': 1, 'Singapore': 1, 'Somalia': 1, 'Turkey': 2})\n"
     ]
    }
   ],
   "source": [
    "'''Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "Create a frequency table of country and breed of cats'''\n",
    "\n",
    "cat_pi = requests.get('https://api.thecatapi.com/v1/breeds')\n",
    "data = cat_pi.json()\n",
    "\n",
    "import numpy\n",
    "def metric_weights(data):\n",
    "    metric_weights = []\n",
    "\n",
    "    for breed in data:\n",
    "        metric_weights.append(\n",
    "            (int(breed['weight']['metric'].split()[0]) + int(breed['weight']['metric'].split()[-1])) / 2)\n",
    "\n",
    "    median = numpy.median(metric_weights)\n",
    "    mean = numpy.mean(metric_weights)\n",
    "    min_metric = min(metric_weights)\n",
    "    max_metric = max(metric_weights)\n",
    "    sd = numpy.std(metric_weights)\n",
    "    print(\"WEIGHT DATA\")\n",
    "    print(\"Standard Deviation: %0.2f\" % sd)\n",
    "    print(\"Minimum:\", min_metric)\n",
    "    print(\"Maximum:\", max_metric)\n",
    "    print(\"Median:\", median)\n",
    "    print(\"Mean: %0.2f\" % mean)\n",
    "metric_weights(data)\n",
    "\n",
    "#II\n",
    "def life_spans(data):\n",
    "    lifespans = []\n",
    "    for breed in data:\n",
    "        lifespans.append((int(breed['life_span'].split()[0]) + int(breed['life_span'].split()[-1])) / 2)\n",
    "\n",
    "    median = numpy.median(lifespans)\n",
    "    mean = numpy.mean(lifespans)\n",
    "    min_span = min(lifespans)\n",
    "    max_span = max(lifespans)\n",
    "    sd = numpy.std(lifespans)\n",
    "    print(\"LIFESPAN DATA\")\n",
    "    print(\"Standard Deviation: %0.2f\" % sd)\n",
    "    print(\"Minimum:\", min_span)\n",
    "    print(\"Maximum:\", max_span)\n",
    "    print(\"Median:\", median)\n",
    "    print(\"Mean: %0.2f\" % mean)\n",
    "life_spans(data)\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    cat_breeds = response.json()\n",
    "else:\n",
    "    print(\"Failed to retrieve information from API\")\n",
    "    \n",
    "#III\n",
    "from collections import defaultdict \n",
    "frequency_table = defaultdict(int)\n",
    "breed_info = {}\n",
    "for breed in cat_breeds:\n",
    "    breed_info[breed['name']] = breed['origin']\n",
    "for breed in breed_info.values():\n",
    "    frequency_table[breed] += 1\n",
    "\n",
    "print(frequency_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from collections import defaultdict\n",
    "frequency_table = defaultdict(int)\n",
    "breed_info = {}\n",
    "for breed in cat_breeds:\n",
    "    breed_info[breed['name']] = breed['origin']\n",
    "for breed in breed_info.values():\n",
    "    frequency_table[breed] += 1\n",
    "\n",
    "print(frequency_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "table = soup.find('table', {'border': '1'})\n",
    "rows = table.find_all('tr')[1:]\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    name = cells[0].text.strip()\n",
    "    print(f'{name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arewadatascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
